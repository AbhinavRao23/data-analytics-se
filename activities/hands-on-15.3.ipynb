{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some basic libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_context('paper')\n",
    "# A helper function for downloading files\n",
    "import requests\n",
    "import os\n",
    "def download(url, local_filename=None):\n",
    "    \"\"\"\n",
    "    Downloads the file in the ``url`` and saves it in the current working directory.\n",
    "    \"\"\"\n",
    "    data = requests.get(url)\n",
    "    if local_filename is None:\n",
    "        local_filename = os.path.basename(url)\n",
    "    with open(local_filename, 'wb') as fd:\n",
    "        fd.write(data.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-on Activity 15.3: Diagnostics for posterior predictive\n",
    "\n",
    "## Objectives\n",
    "\n",
    "+ To introduce measures that quantify how good the posterior predictive distribution is.\n",
    "\n",
    "## Example (Quadratic)\n",
    "\n",
    "We start with our quadratic synthetic example because we know that our model is adequate.\n",
    "You will see how the standarized errors will turn out perfect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The training data:\n",
    "num_obs = 20\n",
    "x = -1.0 + 2 * np.random.rand(num_obs)\n",
    "w0_true = -0.5\n",
    "w1_true = 1.0\n",
    "w2_true = 2.0\n",
    "sigma_true = 0.1\n",
    "y = w0_true + w1_true * x + w2_true * x ** 2 + sigma_true * np.random.randn(num_obs)\n",
    "\n",
    "# Make some validation data\n",
    "num_valid = 50\n",
    "x_valid = -1.0 + 2 * np.random.rand(num_valid)\n",
    "y_valid = w0_true + w1_true * x_valid + w2_true * x_valid ** 2 + sigma_true * np.random.randn(num_valid)\n",
    "\n",
    "# Let's plot the data\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "ax.plot(x, y, 'x', label='Observed data')\n",
    "ax.plot(x_valid, y_valid, 'o', label='Validation data')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also copy-paste the code for creating design matrices for the three generalized linear models we have considered so far:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_polynomial_design_matrix(x, degree):\n",
    "    \"\"\"\n",
    "    Returns the polynomial design matrix of ``degree`` evaluated at ``x``.\n",
    "    \"\"\"\n",
    "    # Make sure this is a 2D numpy array with only one column\n",
    "    assert isinstance(x, np.ndarray), 'x is not a numpy array.'\n",
    "    assert x.ndim == 2, 'You must make x a 2D array.'\n",
    "    assert x.shape[1] == 1, 'x must be a column.'\n",
    "    # Start with an empty list where we are going to put the columns of the matrix\n",
    "    cols = []\n",
    "    # Loop over columns and add the polynomial\n",
    "    for i in range(degree+1):\n",
    "        cols.append(x ** i)\n",
    "    return np.hstack(cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fit the model using automatic relevance determination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Bayesian linear regression class:\n",
    "from sklearn.linear_model import ARDRegression\n",
    "# Select polynomial degree and get design matrix\n",
    "degree = 4\n",
    "# Build the design matrix\n",
    "Phi = get_polynomial_design_matrix(x[:, None], degree)\n",
    "# Do not normalize. ARDRegression seems to have a bug when you do.\n",
    "model = ARDRegression(normalize=False, fit_intercept=False).fit(Phi, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's visualize the resulting model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = np.sqrt(1.0 / model.alpha_)\n",
    "xx = np.linspace(-1, 1, 100)\n",
    "Phi_xx = get_polynomial_design_matrix(xx[:, None], degree)\n",
    "yy_mean, yy_measured_std = model.predict(Phi_xx, return_std=True)\n",
    "yy_std = np.sqrt(yy_measured_std ** 2 - sigma**2)\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "ax.plot(xx, yy_mean, 'r')\n",
    "# Epistemic lower bound\n",
    "yy_le = yy_mean - 2.0 * yy_std\n",
    "# Epistemic upper bound\n",
    "yy_ue = yy_mean + 2.0 * yy_std\n",
    "# Epistemic + aleatory lower bound\n",
    "yy_lae = yy_mean - 2.0 * yy_measured_std\n",
    "# Episemic + aleatory upper bound\n",
    "yy_uae = yy_mean + 2.0 * yy_measured_std\n",
    "ax.fill_between(xx, yy_le, yy_ue, color='red', alpha=0.25)\n",
    "ax.fill_between(xx, yy_lae, yy_le, color='green', alpha=0.25)\n",
    "ax.fill_between(xx, yy_ue, yy_uae, color='green', alpha=0.25)\n",
    "# plot the data again\n",
    "ax.plot(x, y, 'kx', label='Observed data')\n",
    "# The true connection between x and y\n",
    "yy_true = w0_true + w1_true * xx + w2_true * xx ** 2\n",
    "# overlay the true \n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$y$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now let's make predictions on the validation data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Phi_valid = get_polynomial_design_matrix(x_valid[:, None], degree)\n",
    "y_predict, y_std = model.predict(Phi_valid, return_std=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's do the observations vs predictions plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=150)\n",
    "ax.plot(y_predict, y_valid, 'o')\n",
    "yys = np.linspace(y_valid.min(), y_valid.max(), 100)\n",
    "ax.plot(yys, yys, 'r-');\n",
    "ax.set_xlabel('Predictions')\n",
    "ax.set_ylabel('Observations');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's okay. However, notice that the predictions do not fall on the red line because there is a little bit of noise on the observations.\n",
    "\n",
    "Let's now compute the standarized errors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = (y_valid - y_predict) / y_std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember, that if the model is correct, the standarized errors must follow a standard normal.\n",
    "There are various ways to check this.\n",
    "First, let's just plot them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=150)\n",
    "idx = np.arange(1, eps.shape[0] + 1)\n",
    "# The standarized errors\n",
    "ax.plot(idx, eps, 'o', label='Standarized errors')\n",
    "# The 97.5% quantile of the normal as a red dashed line\n",
    "ax.plot(idx, 1.96 * np.ones(eps.shape[0]), 'r--')\n",
    "# The 2.5% quantile of the normal as a red dashed line\n",
    "ax.plot(idx, -1.96 * np.ones(eps.shape[0]), 'r--')\n",
    "ax.set_xlabel('$i$')\n",
    "ax.set_ylabel('$\\epsilon_i$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the majority of the standarized errors fall within the 95% central credible interval for $N(0,1)$.\n",
    "This is an indication that the model is good.\n",
    "\n",
    "The other plot we can do is the histogram of the standarized errors compared to the probability density of the standard normal:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you wanted to get the samples from the posterior?\n",
    "You would have to do a little bit of manual work to translate the posterior weights and their variance back to the original values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "ax.hist(eps, alpha=0.5, density=True)\n",
    "ee = np.linspace(eps.min(), eps.max(), 100)\n",
    "ax.plot(ee, st.norm.pdf(ee), 'r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not perfect, but a pretty good fit.\n",
    "\n",
    "The final diagnostic is the so call quantile-quantile plot.\n",
    "This compares the empirical quantiles of the standarized errors (computed by building and inverting the empirical cummulative distribution function, see Lecture 9).\n",
    "Here is how to do it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=100)\n",
    "st.probplot(eps, dist=st.norm, plot=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is also indicative of a pretty good fit.\n",
    "\n",
    "### Questions\n",
    "\n",
    "+ Rerun the code blocks above with a large number of training observations, say 100. Did the diagnosics improve or are they the same?\n",
    "+ Keep the number of training observations to 100 and change the validation points to 1000. How do the diagnostics look like now?\n",
    "+ Let's now try a model that is not adequate for the data. Set the polynomial degree to 1 and rerun everything. How do the diagnostics look like now?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
