{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some basic libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_context('paper')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-On Activity 7.3: Sampling the categorical\n",
    "\n",
    "## Objectives\n",
    "\n",
    "+ Demonstrate how we can sample from the Categorical distribution using uniform samples.\n",
    "\n",
    "\n",
    "## Readings\n",
    "\n",
    "+ These notes.\n",
    "\n",
    "## Sampling the Bernoulli distribution\n",
    "The Bernoulli distribution arises from a binary random variable representing the outcome of an experiment with a given probability of success.\n",
    "Let us encode success with 1 and failure with 0.\n",
    "It is a special case of the Categorical (2 labels).\n",
    "Then, we say that the random variable\n",
    "$$\n",
    "X\\sim \\operatorname{Bernoulli}(\\theta),\n",
    "$$\n",
    "is a Bernoulli random variable with parameter $\\theta$ if:\n",
    "$$\n",
    "X = \\begin{cases}\n",
    "1,\\;\\text{with probability}\\;\\theta,\\\\\n",
    "0,\\;\\text{otherwise}.\n",
    "\\end{cases}\n",
    "$$\n",
    "To sample from it, we do the following steps:\n",
    "\n",
    "+ Sample a uniform number $u$ (i.e., a number of $U([0,1])$).\n",
    "\n",
    "+ If $u\\le \\theta$, then set $x = 1$.\n",
    "\n",
    "+ Otherwise, set $x = 0$.\n",
    "\n",
    "Let's see if this process does indeed produce the desired result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_bernoulli(theta):\n",
    "    \"\"\"\n",
    "    Samples from the Bernoulli.\n",
    "    \n",
    "    Arguments:\n",
    "        theta    -    The probability of success.\n",
    "    \"\"\"\n",
    "    u = np.random.rand()\n",
    "    if u <= theta:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "for _ in range(10):\n",
    "    print(sample_bernoulli(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's do a histogram like before\n",
    "N = 1000\n",
    "X = [sample_bernoulli(0.3) for _ in range(N)]\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "ax.hist(X, alpha=0.5)\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$p(x)$');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok, it looks fine. About $\\theta N$ samples went to 1 and $(1-\\theta)N$ samples went to 0.\n",
    "\n",
    "Of course, we have already seen that this is implemented in scipy.stats.\n",
    "Here is a quick reminder of that code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "X = st.bernoulli(0.3)\n",
    "X.rvs(size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sampling the $K$-label Categorical\n",
    "Consider a generic discrete random variable $X$ taking $K$ different values.\n",
    "Without loss of generality, you may assume that these values are integers $\\{0, 1,2,\\dots,K-1\\}$ (they are just the labels of the discrete objects anyway).\n",
    "Let us assume that\n",
    "$$\n",
    "p(X=k) = p_k,\n",
    "$$\n",
    "where, of course, we must have:\n",
    "$$\n",
    "p_k \\ge 0,\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\sum_{k=0}^{K-1} p_k = 1.\n",
    "$$\n",
    "Remember, that an succinct way to write this is using the Dirac delta:\n",
    "$$\n",
    "p(x) = \\sum_{k=0}^{K-1}p_k\\delta(x-k).\n",
    "$$\n",
    "In any case, here is how you sample from such a distribution:\n",
    "\n",
    "+ Draw a uniform sample $u$.\n",
    "+ Find the index $j\\in\\{0,1,\\dots,K-1\\}$ such that:\n",
    "$$\n",
    "\\sum_{k=0}^{j-1}p_k \\le u < \\sum_{k=0}^jp_k.\n",
    "$$\n",
    "+ Then, your sample is $j$.\n",
    "\n",
    "Let's code it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_categorical(p):\n",
    "    \"\"\"\n",
    "    Sample from a discrete probability density.\n",
    "    \n",
    "    Arguments:\n",
    "        p      -   An array specifying the probability of each possible state.\n",
    "                   The number of states ``m=len(p)``.    \n",
    "    \"\"\"\n",
    "    K = len(p)\n",
    "    u = np.random.rand()\n",
    "    c = 0.\n",
    "    for j in range(K):\n",
    "        c += p[j]\n",
    "        if u <= c:\n",
    "            return j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test it with a four-state discrete random variable with probabilities\n",
    "p = [0.2, 0.3, 0.4, 0.1]\n",
    "# Let's take 1,000 samples\n",
    "N = 100\n",
    "# The code below is known as a Generator\n",
    "# https://wiki.python.org/moin/Generators\n",
    "# I use it to avoid writing a for loop. It is shorter.\n",
    "X = [sample_categorical(p) for _ in range(N)]\n",
    "# and do the empirical histrogram\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "ax.hist(X, alpha=0.5)\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$p(x)$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of course, ``scipy.stats`` already implements this functionality. Let's compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = len(p)\n",
    "X_st = st.rv_discrete(values=(np.arange(K), p))\n",
    "x_st_samples = X_st.rvs(size=N)\n",
    "\n",
    "# Let's compare the two histograms\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "ax.hist(X, alpha=0.5, label='Our implementation')\n",
    "ax.hist(x_st_samples, alpha=0.5, label='Scipy.stats implementation')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$p(x)$')\n",
    "plt.legend(loc='best')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "\n",
    "+ It looks like there is a lot of variability every time you run the results. You need to go back to the code and increase the number of samples $N$ until the results stop changing. Then you should be able to observe that our code does exactly the same thing as ``scipy.stats.rv_discrete``."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
