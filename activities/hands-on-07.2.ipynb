{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import some basic libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "sns.set_context('paper')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hands-On Activity 7.2: Sampling the uniform\n",
    "\n",
    "## Objectives\n",
    "\n",
    "+ Demonstrate how we can sample from the uniform distribution using PRNGs.\n",
    "\n",
    "\n",
    "## Readings\n",
    "\n",
    "+ These notes.\n",
    "\n",
    "## Sampling from the uniform distribution\n",
    "\n",
    "If we have a PRNG that samples between zero and a big integer, say $m$, we can create a generator that samples from the uniform distribution.\n",
    "If $d$ is the sample from the PRNG, then\n",
    "$$\n",
    "x = \\frac{d}{m},\n",
    "$$\n",
    "is approximately uniformly distributed.\n",
    "Let's experiment with this idea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The maximum integer\n",
    "m = 6012119\n",
    "\n",
    "def lcg(x, a=123456, b=978564, m=6012119):\n",
    "    \"\"\"\n",
    "    Arguments:\n",
    "        x     -   The previous number in the sequence.\n",
    "        a     -   A big integer.\n",
    "        b     -   Another big integer.\n",
    "        m     -   Another big integer.\n",
    "    \"\"\"\n",
    "    return (a * x + b) % m\n",
    "\n",
    "# First a uniform random generator based on lcg\n",
    "lcg_seed = 123456 # A seed of lcg\n",
    "lcg_state = lcg_seed # Internal state of lcg\n",
    "def unif_lcg():\n",
    "    \"\"\"\n",
    "    Samples from the uniform using LCG.\n",
    "    \"\"\"\n",
    "    global lcg_state\n",
    "    lcg_state = lcg(lcg_state)\n",
    "    return lcg_state / (1. * m) # The 1. in the denominator ensures\n",
    "                                # that the division is done in floating point arithmetic\n",
    "print('LCG Uniform Samples:')\n",
    "for _ in range(5):\n",
    "    print(unif_lcg())\n",
    "\n",
    "# And let's also do it with Mersenne Twister from numpy\n",
    "np.random.seed(123456)\n",
    "def unif_mt():\n",
    "    \"\"\"\n",
    "    Samples from the uniform using the MT.\n",
    "    \"\"\"\n",
    "    return np.random.randint(0, m) / (1. * m)\n",
    "print('\\nMT Uniform Samples:')\n",
    "for _ in range(5):\n",
    "    print(unif_mt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which one of the two is better? There are many statistical tests that we would like our uniform random number generator to go through. First (and most importantly) the empirical histograms of the generated numbers should be uniform. Let's test this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many numbers to sample:\n",
    "N = 100\n",
    "lcg_X = [unif_lcg() for _ in range(N)]\n",
    "mt_X = [unif_mt() for _ in range(N)]\n",
    "# Plot the histograms\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "ax.hist(lcg_X, density=True, alpha=0.5, label='LGC_unif')\n",
    "ax.hist(mt_X, density=True, alpha=0.5, label='MT_unif')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$p(x)$')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This was a rough visual test.\n",
    "We can do better.\n",
    "We can compare the [empirical CDF](https://en.wikipedia.org/wiki/Empirical_distribution_function) of each one of these algorithms with the ideal CDF, i.e., that of a real uniform.\n",
    "But what is the empirical CDF of a bunch of samples $x_{1:N}$?\n",
    "It is defined as follows:\n",
    "$$\n",
    "\\hat{F}_N(x) = \\frac{\\text{number of elements in sample}\\;\\le x}{N} = \\frac{1}{N}\\sum_{n=1}^N 1_{(-\\infty, x_i]}(x).\n",
    "$$\n",
    "We are going to explain in what sense the empirical CDF approximates the true PDF in Lecture 9.\n",
    "For now, let's just use it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(x):\n",
    "    \"\"\"\n",
    "    The empirical distribution function of scalar samples.\n",
    "    \n",
    "    From: https://stackoverflow.com/questions/15792552/numpy-scipy-equivalent-of-r-ecdfxx-function\n",
    "    \"\"\"\n",
    "    xs = np.sort(x)\n",
    "    ys = np.arange(1, len(xs)+1)/float(len(xs))\n",
    "    return xs, ys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's plot the empirical CDF of each of the samples and plot it against $F(x) = x$ (the true CDF of the uniform)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(dpi=150)\n",
    "ax.plot(*ecdf(lcg_X), label='LCG')\n",
    "ax.plot(*ecdf(mt_X), label='MT')\n",
    "ax.plot(np.linspace(0, 1), np.linspace(0, 1), label='Uniform')\n",
    "ax.set_xlabel('$x$')\n",
    "ax.set_ylabel('$\\hat{F}_N(x)$')\n",
    "plt.legend(loc='best');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is still visual. The [Kolmogorov-Smirnov test](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test) summarizes calculate a distance between the empirical distribution and the ideal one.\n",
    "It is defined as follows:\n",
    "$$\n",
    "D_N = \\sup_x |F(x) - \\hat{F}_N(x)|,\n",
    "$$\n",
    "where (if you don't know what it is) you can think of the supremum ($\\sup$) as just the maximum.\n",
    "In other words, $D_N$ is the maximum absolute difference between $F(x)$ and $\\hat{F}_N(x)$.\n",
    "Let's see what we get for LCG and MT compared to the uniform:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as st\n",
    "D_lcg, p_val_lcg = st.kstest(lcg_X, 'uniform')\n",
    "D_mt, p_val_mt = st.kstest(mt_X, 'uniform')\n",
    "print('KS statistic for LCG vs uniform: {0:1.2f}'.format(D_lcg))\n",
    "print('KS statistic for MT vs uniform: {0:1.2f}'.format(D_mt))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question\n",
    "+ Hmm, we probably need to increase the number of samples to observe this statistic better. Increase $N$ from 100 to $1,000$ and then to $10,000$. How do the distributions look like now?\n",
    "\n",
    "+ A second thing that we would like to test is whether or not consecutive numbers are all independent (Idependent identically distributed). Unfortunately, we need more theory than we know to do this.\n",
    "\n",
    "+ For future reference, note that you should not really use ``unif_mt`` to generate uniform random numbers. Numpy already implements this in ``numpy.random.rand``. We provide an example right below. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate some random numbers with numpy's unif_mt:\n",
    "X = np.random.rand(10)\n",
    "print(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
